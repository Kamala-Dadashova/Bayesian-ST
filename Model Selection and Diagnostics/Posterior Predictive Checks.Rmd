---
title: 
output: pdf_document
---

\section{Bayesian p-values for the Guns laws data}


The data for this analysis come from “Firearm legislation and firearm mortality in the USA: a cross-sectional, state-level study” by Kalesan et. al. (2016). The response variable, $Y_i$, s the number of firearm-related deaths in 2010 in state $i$. This is regressed onto five potential confounders $Z_{ij}$.

The covariates of interest are the indicators of whether the state has certain gun laws. Let $X_{il}$ ndicate that state $i$ has law number $l$. In this example, we simply use the number of laws $X_i=\sum_{l}X_{il}$ as the covariate.

In this analysis our objective is illustrate the use of posterior predictive checks to verify that the model fits well. We compare two models:

Model 1 - Poisson regression: The first model is the Poisson model we have fit previously 

$$Y_i \sim \mbox{Poisson}(\lambda_i)\mbox{  where } \lambda_i=N_i\exp(\alpha + \sum_{j=1}^5Z_{ij}\beta_j+X_{i}\beta_6)$$

and $N_i$ s the state's population.

Model 2 - Negative-binomial regression: A limitation of the Poisson likelihood is that the variance equals the mean. To allow for a larger variance than the mean (i.e., overdispersion) we replace the Poisson likelihood with the negative binomial likelihood the same mean $\lambda_i$ and over-dispersion parameter $m>0$. 

$$Y_i \sim \mbox{NB}\left(\frac{m}{\lambda_i+m},m\right).$$

Posterior predictive checks are performed for the following test statistics:

$$D_1(Y) = \mbox{max}(Y_1,…,Y_n)$$
$$D_2(Y) = \mbox{min}(Y_1,…,Y_n)$$

$$D_3(Y) = \mbox{max}(Y_1,…,Y_n) - \mbox{min}(Y_1,…,Y_n)$$

$$D_4(Y) = \mbox{max}(Y_1/N_1,…,Y_n/N_n)$$

$$D_5(Y) = \mbox{min}(Y_1/N_1,…,Y_n/N_n)$$

$$D_6(Y) = \mbox{max}(Y_1/N_1,…,Y_n/N_n)-\mbox{min}(Y_1/N_1,…,Y_n/N_n)$$

\section{1. Load the data and libraries}

```{r,echo=FALSE}
load("//Users/kamaladadashova/Documents/DoctoralCourses/Applied Bayesian Statistics/Lecture Notes with Assignments/Week 7 Model Comparisions/guns.RData")
```

```{r}
 X  <- rowSums(X)
 n  <- length(Y)
```

\section{2. Two competing models:}

```{r}
# (1) Poisson regression

 model_string1 <- "model{

  # Likelihood
  for(i in 1:n){
    Y[i]           ~ dpois(lambda[i])
    log(lambda[i]) <- log(N[i]) + alpha + inprod(Z[i,],beta[1:5]) + X[i]*beta[6]
  }

  #Priors
   for(j in 1:6){
      beta[j] ~ dnorm(0,0.1)
   }
   alpha ~ dnorm(0,0.1)


  # Posterior preditive checks
  for(i in 1:n){
    Y2[i]    ~ dpois(lambda[i])
    rate[i] <- Y2[i]/N[i]
  }
  D[1] <- min(Y2[])
  D[2] <- max(Y2[])
  D[3] <- max(Y2[])-min(Y2[])
  D[4] <- min(rate[])
  D[5] <- max(rate[])
  D[6] <- max(rate[])-min(rate[])

 }"


 # (2) Over-dispersed Poisson
 model_string2 <- "model{

  # Likelihood (note hierarchical centering)
  for(i in 1:n){
    Y[i]            ~ dnegbin(q[i],m)
    q[i]           <- m/(m+N[i]*lambda[i])
    log(lambda[i]) <- alpha + inprod(Z[i,],beta[1:5]) + X[i]*beta[6]
  }

  #Priors
   for(j in 1:6){
      beta[j] ~ dnorm(0,0.1)
   }
   alpha ~ dnorm(0,0.1)
   m     ~ dgamma(0.1,0.1)

  # Posterior preditive checks
  for(i in 1:n){
    Y2[i]    ~ dnegbin(q[i],m)
    rate[i] <- Y2[i]/N[i]
  }

  D[1] <- min(Y2[])
  D[2] <- max(Y2[])
  D[3] <- max(Y2[])-min(Y2[])
  D[4] <- min(rate[])
  D[5] <- max(rate[])
  D[6] <- max(rate[])-min(rate[])

 }"
```

\section{3. Fit the two models}

```{r,echo=TRUE,out.width="50%"}
library(rjags)
model1 <- jags.model(textConnection(model_string1), 
                  data = list(Y=Y,N=N,n=n,X=X,Z=Z),n.chains=1,
                  quiet=TRUE)
update(model1, 10000, progress.bar="none")
samps1 <- coda.samples(model1, 
          variable.names=c("D","beta"), 
          n.iter=20000, progress.bar="none")
plot(samps1)
```

```{r}
 print(summary(samps1))
```

```{r,echo=TRUE,out.width="50%"}
D1  <- samps1[[1]]
model2 <- jags.model(textConnection(model_string2), 
                  data = list(Y=Y,N=N,n=n,X=X,Z=Z),n.chains=1,
                  quiet=TRUE)
update(model2, 10000, progress.bar="none")
samps2 <- coda.samples(model2, 
          variable.names=c("D","beta"), 
          n.iter=20000, progress.bar="none")
plot(samps2)
```

```{r}
print(summary(samps2))
```

```{r}
D2  <- samps2[[1]]
```

\section{4. Bayesian p-values}

```{r,echo=TRUE,out.width="50%"}
# Compute rate as the ratio of Y to N
rate <- Y / N

# Create a vector with min, max, and range for Y and rate
D0 <- c(min(Y), max(Y), diff(range(Y)),
        min(rate), max(rate), diff(range(rate)))

# Define names for the vector D0
Dnames <- c("Min Y", "Max Y", "Range Y", "Min rate", "Max rate", "Range rate")

# Initialize vectors for p-values
pval1 <- numeric(6)
names(pval1) <- Dnames
pval2 <- pval1

# Loop through each element to compute test statistics and plot densities
for (j in 1:6) {
  # Plot density for D1
  plot(density(D1[, j]), xlim = range(c(D0[j], D1[, j], D2[, j])),
       xlab = "D", ylab = "Posterior probability", main = Dnames[j])
  
  # Add density line for D2
  lines(density(D2[, j]), col = 2)
  
  # Add a vertical line for the value in D0
  abline(v = D0[j], col = 3)
  
  # Add a legend to the plot
  legend("topleft", legend = c("Poisson", "NB", "Data"), lty = 1, col = 1:3, bty = "n")
  
  # Compute p-values
  pval1[j] <- mean(D1[, j] > D0[j]) 
  pval2[j] <- mean(D2[, j] > D0[j])  
}

# Print p-values for inspection
print(pval1)
print(pval2)


```


\section{Conclusion}

In this analysis, two statistical models were evaluated to assess their fit to the data on firearm-related deaths in the USA in 2010. The models compared were a Poisson regression model and a negative binomial regression model. 

\begin{itemize}
    \item \textbf{Poisson Regression Model}: The Poisson model assumes that the number of firearm-related deaths follows a Poisson distribution, where the rate parameter $\lambda_i$ is determined by the state's population and other covariates. The limitation of this model is that it assumes the variance is equal to the mean, which may not be realistic for the data at hand.
    \item \textbf{Negative Binomial Regression Model}: The negative binomial model addresses the overdispersion present in the data by allowing for a variance greater than the mean. This model incorporates an additional over-dispersion parameter $m$ to better fit the data.
\end{itemize}

\subsection{Posterior Predictive Checks}

Posterior predictive checks were performed using several test statistics, including the minimum and maximum of the observed counts and rates, as well as their ranges. The results of these checks were used to compute Bayesian p-values for both models.

\begin{itemize}
    \item \textbf{Poisson Regression Model}: The Poisson model showed several p-values near zero or one, indicating a poor fit to the data. This suggests that the Poisson model may not adequately capture the variability in the number of firearm-related deaths.
    \item \textbf{Negative Binomial Regression Model}: The negative binomial model provided a better fit to the data, with p-values indicating a more reasonable match between the observed and predicted values. This model is more flexible in accounting for the overdispersion in the data.
\end{itemize}


